services:
  # Redis - Message Queue & Cache
  redis:
    image: redis:7-alpine
    ports:
      - "6380:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    networks:
      - ai-coder-network
    restart: unless-stopped

  # Backend API Service
  backend-api:
    build:
      context: .
      dockerfile: Dockerfile.backend
    ports:
      - "8500:8000"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-pro}
      - TEMPERATURE=${TEMPERATURE:-0.7}
      - MAX_TOKENS=${MAX_TOKENS:-4000}
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - DEBUG=${DEBUG:-false}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./backend:/app
      - backend_logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - ai-coder-network
    restart: unless-stopped

  # Agent Worker Services (Scalable)
  agent-worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-pro}
      - TEMPERATURE=${TEMPERATURE:-0.7}
      - MAX_TOKENS=${MAX_TOKENS:-4000}
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - WORKER_TYPE=agent_worker
    volumes:
      - ./backend:/app
      - worker_logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - ai-coder-network
    restart: unless-stopped

  # Frontend Service
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    ports:
      - "3002:80"
    environment:
      - REACT_APP_API_URL=http://localhost:8500
    depends_on:
      - backend-api
    networks:
      - ai-coder-network
    restart: unless-stopped

  # Nginx Load Balancer & API Gateway
  nginx-gateway:
    image: nginx:alpine
    ports:
      - "9080:80"
      - "9443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/api-gateway.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - backend-api
      - frontend
    networks:
      - ai-coder-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 10s
      timeout: 3s
      retries: 3

  # Monitoring - Redis Commander (Optional)
  redis-commander:
    image: rediscommander/redis-commander:latest
    environment:
      - REDIS_HOSTS=local:redis:6379
    ports:
      - "8082:8081"
    depends_on:
      - redis
    networks:
      - ai-coder-network
    restart: unless-stopped
    profiles:
      - monitoring

volumes:
  redis_data:
    driver: local
  backend_logs:
    driver: local
  worker_logs:
    driver: local

networks:
  ai-coder-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

